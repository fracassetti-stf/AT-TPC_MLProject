{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fraca\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\fraca\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\fraca\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\fraca\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\fraca\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\fraca\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\fraca\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\fraca\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\fraca\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\fraca\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\fraca\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\fraca\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helper_functions_CNN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-236dc8ab6e58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhelper_functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhelper_functions_CNN\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m# This is simply an alias for convenience\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'helper_functions_CNN'"
     ]
    }
   ],
   "source": [
    "# Common import\n",
    "\n",
    "import os\n",
    "\n",
    "import math\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D # <--- This is important for 3d plotting \n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, f1_score, \n",
    "                             matthews_corrcoef, roc_curve, roc_auc_score, classification_report)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from functools import reduce # for union of more than 2 arrays\n",
    "BatchNormalization\n",
    "from helper_functions import *\n",
    "\n",
    "# This is simply an alias for convenience\n",
    "layers = tf.keras.layers\n",
    "\n",
    "#Fixing seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading DataSet\n",
    "local_data = './DataFiles/Mg22_alphaalpha_digiSim.h5'\n",
    "hf = h5py.File(local_data, 'r')\n",
    "\n",
    "# The function load_fata (helper_functions.py) performes the operation mentioned above.\n",
    "DataList, Labels = load_data(hf)\n",
    "hf.close() # closing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ordered index list : [0,1,2,...,len(DataList)]\n",
    "x_idx = np.arange(len(DataList))\n",
    "\n",
    "# Splitting in train+validation (90% in total), and test (10%)\n",
    "trainval_idx, test_idx, not_used1, not_used2 = train_test_split(x_idx, x_idx, test_size = 0.10)\n",
    "\n",
    "# Splitting the remaining part (90% of the original DataSet): Training (90%) and Validation (10%)\n",
    "train_idx, val_idx, not_used3, not_used4 = train_test_split(trainval_idx, trainval_idx, test_size = 0.10)\n",
    "\n",
    "print(\"Dataset was divided into:\")\n",
    "print(str(len(train_idx)) + \" training events,\")\n",
    "print(str(len(val_idx)) + \"  validation events, and\")\n",
    "print(str(len(test_idx)) + \"  test events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Features through the function calc_features (helper_functions.py)\n",
    "(MeanXPerEvent, MeanYPerEvent, MeanZPerEvent, SumAPerEvent, \n",
    "PadsPerEvent, MeanWeightedXPerEvent, MeanWeightedYPerEvent, \n",
    "StDevXPerEvent, StDevYPerEvent, StDevZPerEvent,FracClosePtsPerEvent) = calc_features(DataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some definition before plotting \n",
    "\n",
    "# Splitting train_ind into beam and reaction indexes\n",
    "train_r_idx = [] # List of indexes of \"Reaction\" training event\n",
    "train_b_idx = [] # List of indexes of \"Beam\" training event\n",
    "\n",
    "for i in train_idx:\n",
    "    if Labels[i]>0.5:\n",
    "        train_r_idx.append(i) # Indexes of \"Reaction\" training data\n",
    "    else:\n",
    "        train_b_idx.append(i) # Indexes of \"Beam\" training data\n",
    "        \n",
    "# Converting into numpy array for later use\n",
    "train_r_idx = np.array(train_r_idx) \n",
    "train_b_idx = np.array(train_b_idx)\n",
    "\n",
    "# Defining colours for histograms and scatter plot\n",
    "b_color = 'black'\n",
    "r_color = 'blue'\n",
    "\n",
    "#Define legend for 2d (scatter)plots\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='Beam', markerfacecolor=b_color, markersize=15),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='Reaction', markerfacecolor=r_color, markersize=15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xSimple = np.zeros((len(DataList),5)) # Design Matrix with 5 features\n",
    "\n",
    "# Filling the matrix\n",
    "for i in range(len(DataList)):\n",
    "    xSimple[i][0] = MeanZPerEvent[i]\n",
    "    xSimple[i][1] = StDevXPerEvent[i]\n",
    "    xSimple[i][2] = FracClosePtsPerEvent[i]\n",
    "    xSimple[i][3] = SumAPerEvent[i]\n",
    "    xSimple[i][4] = PadsPerEvent[i]\n",
    "# not used \n",
    "    #xSimple[i][0] = MeanXPerEvent[i]\n",
    "    #xSimple[i][1] = MeanYPerEvent[i]\n",
    "    #xSimple[i][1] = StDevYPerEvent[i]\n",
    "    #xSimple[i][5] = StDevZPerEvent[i]\n",
    "\n",
    "# Dividing entries in train, val and test\n",
    "xSimple_train = xSimple[train_idx][:]\n",
    "xSimple_val = xSimple[val_idx][:]\n",
    "xSimple_test = xSimple[test_idx][:]\n",
    "Labels_train = Labels[train_idx]\n",
    "Labels_val = Labels[val_idx]\n",
    "Labels_test = Labels[test_idx]\n",
    "\n",
    "# Converting to DataFrame for better visualization, and for possible later use\n",
    "X= pd.DataFrame(xSimple)\n",
    "print(\"Design Matrix X:\")\n",
    "X.columns = ['Mean Z','stdev(X)','FCP','Total Q','Pads']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(xSimple_train)\n",
    "\n",
    "# Using the standardscaler\n",
    "xSimple_train_stdsc = scaler.transform(xSimple_train)\n",
    "xSimple_val_stdsc = scaler.transform(xSimple_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SF: Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we create an image out of an event??\n",
    "This is how an event looks like: \n",
    "```\n",
    "DataList[0]\n",
    "```\n",
    "We want to convert this in a 2D image, to use for the CNN algorithm. The first thought is to use the the (x,y) plane, and pixel the surface in ordet to save it as a 2D matrix. The logic choice would be to use the charge deposited on that pad as pixel value - we use the number of time the pad fired in that event, since it leads to better results.\n",
    "\n",
    "**Generating the 2D matrix**: we first need how to set the grid on the x,y place. The exercise does not give us the dimension of the single pads, so we have to figure it out. This can be done in two steps:\n",
    "- Extract the dimension of the x,y projection: In this way we can reconstruct the dimension of the pad plane. \n",
    "- Deduce the dimension of the single pad: We assume that in the simulation the value of x and y was assigned to be the in the center of the pad. We define our pad grid consequently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataList[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 : Get Pad Plane Dimenstion.\n",
    "We can easily extract the dimension of the image we want to create, based on the max/min values of the (x,y)-tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "points, x_lim, y_lim = images_preprocessing(DataList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the cell spacing it is better to plot the values on a graph, and do it manually. We would fail doing it automatically, both because we need a clever way to split the image, and because of rounding errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 : Get Single Pad Dimenstion.\n",
    "First, we plot the superposition of all the projection acquired event by event, in this way the pad structure should become visible. \n",
    "\n",
    "We expect x,y to assume discrete value, and we can extract the increase step. In principle the x and y step may be different (rectangular pads, exagonal, or other shapes), and also the step may differ from region to region. \n",
    "\n",
    "For this exercise purporse, after calculating the step close to the center, we just use the same step along all the pad plane direction, and assume squared pads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get a clear idea of the pad plane structure, their shape, and the spacing between every single pad.\n",
    "using a proper grid to pixel the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the plot of the pad plane we got this information.\n",
    "x_spc = 2.45411777\n",
    "x_shift = x_spc/2\n",
    "y_spc = 2.1422616225\n",
    "y_shift = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the grid\n",
    "show_grid(points, x_lim, y_lim, x_spc, y_spc, x_shift, y_shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Grid trial\n",
    "We do not like that many pads will have for sure no charge, since they do not contain any points. We try to fuse four pads together, and use the new grid as show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new grid (\"ag\" stand for alternative grid)\n",
    "x_spc_ag = x_spc*2\n",
    "y_spc_ag = y_spc*2\n",
    "x_shift_ag = x_spc_ag/4\n",
    "y_shift_ag = 0\n",
    "\n",
    "show_grid(points, x_lim, y_lim, x_spc_ag, y_spc_ag, x_shift_ag, y_shift_ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transalte an event into an image\n",
    "We save two different type of images:\n",
    "- images_Q: pixel value is equal to charge deposited.\n",
    "- images: pixel value is the number of time that pixel fired during the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1st inxes Event, 2nd y, 3rd x\n",
    "\n",
    "Q = []\n",
    "pads = []\n",
    "\n",
    "for i in range(len(points)): # loop on event number\n",
    "    Q.append([])\n",
    "    pads.append([])\n",
    "    for j in range(len(points[i])): # loop on event rows\n",
    "        Q[i].append(DataList[i][j][2]) \n",
    "        pads[i].append(1)\n",
    "\n",
    "\n",
    "images = generate_images(points, Q ,x_lim, y_lim, x_spc_ag, y_spc_ag, x_shift_ag, y_shift_ag)\n",
    "images_1 = generate_images(points, pads,  x_lim, y_lim, x_spc_ag, y_spc_ag, x_shift_ag, y_shift_ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are now created on a grid 236x209 and normalized form (0,255)\n",
    "\n",
    "### Reducing Images Dimenstion\n",
    "We want to reduce the dimension to limit the time to run the model. Also most of the information is contained in the center of the pad plane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with reduced images\n",
    "\n",
    "images_r = reduce_images_dim(images, 60)\n",
    "images_r_1 = reduce_images_dim(images_1, 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_f = fuse_pixels(images_r_1, 2,2)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data (0-255)\n",
    "images_rn= normalize_image_data(images_r)\n",
    "images_rn_1= normalize_image_data(images_r_1)\n",
    "images_f_1= normalize_image_data(images_f)\n",
    "images_n= normalize_image_data(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot some Images\n",
    "\n",
    "\n",
    "plot_images(images_f_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to distinguish between beam - reaction the first choice (images) looks better.\n",
    "\n",
    "### Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "images = np.reshape(images_reduced, (images_reduced.shape[0], 40, 40, 1)) # image, x, y, ch\n",
    "images_Q = np.reshape(images_reduced, (images_reduced.shape[0], 40, 40, 1)) # image, x, y, ch\n",
    "\n",
    "images_train, images_val, labels_train, labels_val = train_test_split(images_Q, Labels)\n",
    "label2_train = to_categorical(labels_train)\n",
    "label2_val = to_categorical(labels_val)\n",
    "\n",
    "print(images.shape)\n",
    "print(\"\")\n",
    "print(images_train.shape)\n",
    "print(images_val.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = tf.keras.Sequential()\n",
    "\n",
    "my_model.add(tf.keras.layers.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=(10, 10),\n",
    "        activation='relu',\n",
    "        padding='same',\n",
    "        input_shape=images.shape[1:] # Shape of a single imag\n",
    "                                )\n",
    "        )\n",
    "\n",
    "my_model.add(BatchNormalization())\n",
    "\n",
    "my_model.add(tf.keras.layers.MaxPooling2D(pool_size=(4, 4)))\n",
    "my_model.add(tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu'))\n",
    "my_model.add(tf.keras.layers.Flatten())\n",
    "my_model.add(tf.keras.layers.Dense(40, activation='relu'))\n",
    "my_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Once the model is defined, we need to compile it. \n",
    "# This is where we specify the loss function, optimizer, and metrics if we want.\n",
    "my_model.compile(\n",
    "    tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.8, beta_2=0.9),\n",
    "    loss='binary_crossentropy', #'sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = my_model.fit(images_train,\n",
    "          labels_train,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          validation_data=(images_val, labels_val));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_nn_plots(history,0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_pred_train_pre = my_model.predict(images_train)\n",
    "CNN_pred_val_pre = my_model.predict(images_val)\n",
    "CNN_pred_train = CNN_pred_train_pre > 0.5\n",
    "CNN_pred_val = CNN_pred_val_pre > 0.5\n",
    "print_model_performance(labels_train, CNN_pred_train, \"Training\")\n",
    "print_model_performance(labels_val, CNN_pred_val, \"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_3d = np.expand_dims(images_reduced,3)\n",
    "images_3d = np.repeat(images_3d,3,3)\n",
    "\n",
    "images_3d.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "images_train, images_val, labels_train, labels_val = train_test_split(images_3d, Labels)\n",
    "\n",
    "model = build_pretrained_vgg_model((dim,dim,3), 2)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_vgg = model.fit(images_train,\n",
    "          labels_train,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=(images_val, labels_val));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_nn_plots(history_vgg,0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_pred_train_pre = model.predict(images_train)\n",
    "VGG_pred_val_pre = model.predict(images_val)\n",
    "VGG_pred_train = VGG_pred_train_pre > 0.5\n",
    "VGG_pred_val = VGG_pred_val_pre > 0.5\n",
    "print(VGG_pred_train)\n",
    "print_model_performance(labels_train, VGG_pred_train, \"Training\")\n",
    "print_model_performance(labels_val, VGG_pred_val, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
